# The following code was written from scrath to gain a better understanding of forward propagation through a CNN

import numpy as np
import pandas as pd
import math
import scipy
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from scipy import misc

# use the MNIST Kaggle dataset:
train = pd.read_csv("C:.../Digit Recognizer/Digit_Recognizer_Train.csv")
test = pd.read_csv("C:.../Digit Recognizer/Digit_Recognizer_Test.csv")

train = pd.DataFrame(data=train)
test_x = pd.DataFrame(data=test)

train_y = pd.DataFrame(data=train[train.columns[0]])
train_x = pd.DataFrame(data=train[train.columns[1:]])

# recalculate pixel values to be between [0,1] rather than [0,255]
train_x = np.multiply(train_x, 1.0 / 255.0)

# display length of pixel vector
image_size = train_x.shape[1]
print('image_size =', format(image_size))

# since the images are square:
image_height = image_width = np.sqrt(image_size).astype(np.uint8)
print('image_height = {0}\nimage_width = {1}'.format(image_height, image_width))

# Reshape an image into a 28x28 matrix 
an_image = train_x.loc[8].values.reshape(image_width, image_height)
an_image.shape

# Output one of the images:
#  
def display(img):
    one_image = train_x.loc[img].values.reshape(image_width, image_height)
    plt.axis('off')
    plt.imshow(one_image, cmap=cm.binary)
    plt.show()

display(37) # the 37 here represents slicing the dataset to display that data point (here the 38th image) 
 
### Create a convolved feature using an example image and filter ###
# Example image
img1 = np.matrix(train_x.loc[10].values.reshape(image_width, image_height))

# Example filter layer:
filter1 = np.matrix('1, 0, -1; 0, 0, 0; -1, 0, 1')
filter1

# Defining the filter height and width
filter_height = filter1.shape[0]
filter_width = filter1.shape[1]
print('filter_height = {0}\nfilter_width = {1}'.format(filter_height, filter_width))


# Function to create a convolved feature:
def convolve(img):
    matrix = train_x.loc[img].values.reshape(image_width, image_height)
    my_arr = []
    for i in range(0,image_height-filter_height): # iterate through matrix rows
        for j in range(0,image_width-filter_width): # iterate through matrix columns
            slice = matrix[i:i+filter_height,j:j+filter_width] # take a subset of the image matrix in order to
            slide = np.multiply(slice, filter1)
            sum1 = np.sum(slide)
            my_arr.append(sum1)
    np.asarray(my_arr) 
    my_mat = np.reshape(my_arr, (25,25))
    my_mat = np.matrix(my_mat)
    
    return my_mat

# Plotting function for the convolved image: 
def plot_conv(img):
    plt.axis('off')
    plt.imshow(convolve(img), cmap=cm.binary)
    plt.show()
    return

plot_conv(37)


# Defining activation functions
# ReLU function:
def ReLU(x):
    y = max(x, 0)
    return y
# sigmoid function:
def sigmoid(x):
    y = 1 / (1 + math.exp(-x))
    return y
# tanh function: 
def tanh(x):
    y = 1 - math.tanh(x)**2
    return y

# Function to push the convolved image through an activation function:
def activate(img):
    my_arr = []
    conv = convolve(img)
    matrix_height = conv.shape[0]
    matrix_width = conv.shape[1]
    for i in range(0, matrix_height):
        for j in range(0, matrix_width):
            spot = conv[i,j]
            spot = ReLU(spot) # change activation function here to change the activation function
            my_arr.append(spot)
    
    np.asarray(my_arr)
    my_mat = np.reshape(my_arr, (matrix_height, matrix_width))
    my_mat = np.matrix(my_mat)
    
    return my_mat

# Plotting function for the activation layer: 
def plot_active(img):
    plt.axis('off')
    plt.imshow(activate(img), cmap=cm.binary)
    plt.show()
    return

plot_active(37)



# Function for the pooling layer:
def pooling(img):
    my_arr = []
    matrix = activate(img)
    matrix_height = matrix.shape[0]
    matrix_width = matrix.shape[1]
    
    # define pooling dimensions so they evenly spread over the image since we're not using zero-padding
    if matrix_height % 2 == 0: 
        pool_dim = 2
    elif matrix_height % 3 == 0:
        pool_dim = 3
    elif matrix_height % 5 == 0:
        pool_dim = 5
    elif matrix_height % 7 == 0:
        pool_dim = 7
    else:
        pool_dim = 1
        
    for i in range(0,matrix_height, pool_dim):
        for j in range(0,matrix_width, pool_dim):
            pool = matrix[i:i+pool_dim, j:j+pool_dim]
            sum_pool = np.sum(pool)
            mean_pool = np.mean(pool)
            max_pool = np.max(pool)
            my_arr.append(max_pool) # specify pooling type here
    
    my_mat_height = int(matrix_height / pool_dim)
    my_mat_width = int(matrix_width / pool_dim)
    np.asarray(my_arr)
    my_mat = np.reshape(my_arr, (my_mat_height, my_mat_width))
    my_mat = np.matrix(my_mat)
    return my_mat

# Plotting function for the pooled image: 
def plot_pool(img):
    plt.axis('off')
    plt.imshow(pooling(img), cmap=cm.binary)
    plt.show()
    return

plot_pool(37)

# Function to apply the softmax function on the pooled matrix:
# Note: not sure if this is the correct way to calculate it since this applies softmax as a piecewise function over the matrix
def softmax(img):
    matrix = pooling(img)
    matrix_height = matrix.shape[0]
    matrix_width = matrix.shape[1]
    inputs = matrix.getA1()
    soft = np.exp(inputs) / float(sum(np.exp(inputs)))
    my_mat = np.reshape(soft, (matrix_height, matrix_width))
    my_mat = np.matrix(my_mat)
    return my_mat

# Plotting function for the pooled image: 
def plot_soft(img):
    plt.axis('off')
    plt.imshow(softmax(img), cmap=cm.binary)
    plt.show()
    return

softmax(4)
